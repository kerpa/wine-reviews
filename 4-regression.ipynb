{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "price = f (points, year, province, region_1, variety, winery)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "    country                                        description  \\\n0     Italy  Aromas include tropical fruit, broom, brimston...   \n1  Portugal  This is ripe and fruity, a wine that is smooth...   \n2        US  Tart and snappy, the flavors of lime flesh and...   \n3        US  Pineapple rind, lemon pith and orange blossom ...   \n4        US  Much like the regular bottling from 2012, this...   \n\n                          designation  points  price           province  \\\n0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n1                            Avidagos      87   15.0              Douro   \n2                                 NaN      87   14.0             Oregon   \n3                Reserve Late Harvest      87   13.0           Michigan   \n4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n\n              region_1           region_2         taster_name  \\\n0                 Etna                NaN       Kerin O’Keefe   \n1                  NaN                NaN          Roger Voss   \n2    Willamette Valley  Willamette Valley        Paul Gregutt   \n3  Lake Michigan Shore                NaN  Alexander Peartree   \n4    Willamette Valley  Willamette Valley        Paul Gregutt   \n\n  taster_twitter_handle                                              title  \\\n0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n3                   NaN  St. Julian 2013 Reserve Late Harvest Riesling ...   \n4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n\n          variety               winery  \n0     White Blend              Nicosia  \n1  Portuguese Red  Quinta dos Avidagos  \n2      Pinot Gris            Rainstorm  \n3        Riesling           St. Julian  \n4      Pinot Noir         Sweet Cheeks  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>description</th>\n      <th>designation</th>\n      <th>points</th>\n      <th>price</th>\n      <th>province</th>\n      <th>region_1</th>\n      <th>region_2</th>\n      <th>taster_name</th>\n      <th>taster_twitter_handle</th>\n      <th>title</th>\n      <th>variety</th>\n      <th>winery</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Italy</td>\n      <td>Aromas include tropical fruit, broom, brimston...</td>\n      <td>Vulkà Bianco</td>\n      <td>87</td>\n      <td>NaN</td>\n      <td>Sicily &amp; Sardinia</td>\n      <td>Etna</td>\n      <td>NaN</td>\n      <td>Kerin O’Keefe</td>\n      <td>@kerinokeefe</td>\n      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n      <td>White Blend</td>\n      <td>Nicosia</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Portugal</td>\n      <td>This is ripe and fruity, a wine that is smooth...</td>\n      <td>Avidagos</td>\n      <td>87</td>\n      <td>15.0</td>\n      <td>Douro</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Roger Voss</td>\n      <td>@vossroger</td>\n      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n      <td>Portuguese Red</td>\n      <td>Quinta dos Avidagos</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>US</td>\n      <td>Tart and snappy, the flavors of lime flesh and...</td>\n      <td>NaN</td>\n      <td>87</td>\n      <td>14.0</td>\n      <td>Oregon</td>\n      <td>Willamette Valley</td>\n      <td>Willamette Valley</td>\n      <td>Paul Gregutt</td>\n      <td>@paulgwine</td>\n      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n      <td>Pinot Gris</td>\n      <td>Rainstorm</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>US</td>\n      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n      <td>Reserve Late Harvest</td>\n      <td>87</td>\n      <td>13.0</td>\n      <td>Michigan</td>\n      <td>Lake Michigan Shore</td>\n      <td>NaN</td>\n      <td>Alexander Peartree</td>\n      <td>NaN</td>\n      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n      <td>Riesling</td>\n      <td>St. Julian</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>US</td>\n      <td>Much like the regular bottling from 2012, this...</td>\n      <td>Vintner's Reserve Wild Child Block</td>\n      <td>87</td>\n      <td>65.0</td>\n      <td>Oregon</td>\n      <td>Willamette Valley</td>\n      <td>Willamette Valley</td>\n      <td>Paul Gregutt</td>\n      <td>@paulgwine</td>\n      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n      <td>Pinot Noir</td>\n      <td>Sweet Cheeks</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/winemag-data-130k-v2.csv',index_col='Unnamed: 0')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 129971 entries, 0 to 129970\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   country                129908 non-null  object \n",
      " 1   description            129971 non-null  object \n",
      " 2   designation            92506 non-null   object \n",
      " 3   points                 129971 non-null  int64  \n",
      " 4   price                  120975 non-null  float64\n",
      " 5   province               129908 non-null  object \n",
      " 6   region_1               108724 non-null  object \n",
      " 7   region_2               50511 non-null   object \n",
      " 8   taster_name            103727 non-null  object \n",
      " 9   taster_twitter_handle  98758 non-null   object \n",
      " 10  title                  129971 non-null  object \n",
      " 11  variety                129970 non-null  object \n",
      " 12  winery                 129971 non-null  object \n",
      "dtypes: float64(1), int64(1), object(11)\n",
      "memory usage: 13.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 111592 entries, 1 to 129970\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   country                111537 non-null  object \n",
      " 1   description            111592 non-null  object \n",
      " 2   designation            79533 non-null   object \n",
      " 3   points                 111592 non-null  int64  \n",
      " 4   price                  111592 non-null  float64\n",
      " 5   province               111537 non-null  object \n",
      " 6   region_1               93580 non-null   object \n",
      " 7   region_2               46568 non-null   object \n",
      " 8   taster_name            88320 non-null   object \n",
      " 9   taster_twitter_handle  83837 non-null   object \n",
      " 10  title                  111592 non-null  object \n",
      " 11  variety                111592 non-null  object \n",
      " 12  winery                 111592 non-null  object \n",
      "dtypes: float64(1), int64(1), object(11)\n",
      "memory usage: 11.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(subset=['price','points','variety'] ,inplace=True)\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df[df['country'].isin(df['country'].value_counts()[df['country'].value_counts()>500].index)]\n",
    "\n",
    "df_country = df['country'].value_counts()\n",
    "df_country.plot(kind='bar',figsize=(10,5),cmap='Pastel1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "count    105383.000000\nmean       2010.642599\nstd           3.640036\nmin        1973.000000\n25%        2009.000000\n50%        2011.000000\n75%        2013.000000\nmax        2017.000000\nName: year, dtype: float64"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract the year from the title column\n",
    "df['year'] = df['title'].str.extract('(\\d{4})',expand=False)\n",
    "df.dropna(subset=['year'],inplace=True)\n",
    "df['year'] = df['year'].astype(int)\n",
    "\n",
    "#keep only the years between 1970 and 2022\n",
    "df = df[df['year']>1970]\n",
    "df = df[df['year']<2022]\n",
    "\n",
    "df['year'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 101731 entries, 1 to 129970\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   points    101731 non-null  int64  \n",
      " 1   price     101731 non-null  float64\n",
      " 2   province  101731 non-null  object \n",
      " 3   region_1  86419 non-null   object \n",
      " 4   variety   101731 non-null  object \n",
      " 5   winery    101731 non-null  object \n",
      " 6   year      101731 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.drop(['description','designation','taster_twitter_handle','taster_name','region_2','title','country'],axis=1, inplace=True)\n",
    "\n",
    "#remove outliers in price\n",
    "df = df[df['price']<100]\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "top_province = df['province'].value_counts()\n",
    "df = df[df['province'].isin(top_province.index[:1000])]\n",
    "\n",
    "top_variety = df['variety'].value_counts()\n",
    "df = df[df['variety'].isin(top_variety.index[:1000])]\n",
    "\n",
    "top_region_1 = df['region_1'].value_counts()\n",
    "df = df[df['region_1'].isin(top_region_1.index[:1000])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "top_winery = df['winery'].value_counts()\n",
    "df = df[df['winery'].isin(top_winery.index[:1000])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 36376 entries, 7 to 129970\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   points    36376 non-null  int64  \n",
      " 1   price     36376 non-null  float64\n",
      " 2   province  36376 non-null  object \n",
      " 3   region_1  36376 non-null  object \n",
      " 4   variety   36376 non-null  object \n",
      " 5   winery    36376 non-null  object \n",
      " 6   year      36376 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "    points  price    province          region_1             variety  \\\n7       87   24.0      Alsace            Alsace      Gewürztraminer   \n9       87   27.0      Alsace            Alsace          Pinot Gris   \n10      87   19.0  California       Napa Valley  Cabernet Sauvignon   \n12      87   34.0  California  Alexander Valley  Cabernet Sauvignon   \n14      87   12.0  California     Central Coast          Chardonnay   \n\n                winery  year  \n7             Trimbach  2012  \n9   Jean-Baptiste Adam  2012  \n10  Kirkland Signature  2011  \n12    Louis M. Martini  2012  \n14            Mirassou  2012  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>points</th>\n      <th>price</th>\n      <th>province</th>\n      <th>region_1</th>\n      <th>variety</th>\n      <th>winery</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>87</td>\n      <td>24.0</td>\n      <td>Alsace</td>\n      <td>Alsace</td>\n      <td>Gewürztraminer</td>\n      <td>Trimbach</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>87</td>\n      <td>27.0</td>\n      <td>Alsace</td>\n      <td>Alsace</td>\n      <td>Pinot Gris</td>\n      <td>Jean-Baptiste Adam</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>87</td>\n      <td>19.0</td>\n      <td>California</td>\n      <td>Napa Valley</td>\n      <td>Cabernet Sauvignon</td>\n      <td>Kirkland Signature</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>87</td>\n      <td>34.0</td>\n      <td>California</td>\n      <td>Alexander Valley</td>\n      <td>Cabernet Sauvignon</td>\n      <td>Louis M. Martini</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>87</td>\n      <td>12.0</td>\n      <td>California</td>\n      <td>Central Coast</td>\n      <td>Chardonnay</td>\n      <td>Mirassou</td>\n      <td>2012</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 36376 entries, 7 to 129970\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   points    36376 non-null  int64  \n",
      " 1   price     36376 non-null  float64\n",
      " 2   province  36376 non-null  object \n",
      " 3   region_1  36376 non-null  object \n",
      " 4   variety   36376 non-null  object \n",
      " 5   winery    36376 non-null  object \n",
      " 6   year      36376 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#One hot encoding of the categorical variables\n",
    "#province, region_1, variety, winery\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "OHE = OneHotEncoder(categories='auto')\n",
    "\n",
    "OHE.fit(df[['province','region_1','variety','winery']])\n",
    "OHE.transform(df[['province','region_1','variety','winery']]).toarray()\n",
    "\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['points', 'price', 'province', 'region_1', 'variety', 'winery', 'year'], dtype='object')"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "#create target variable and features, afterward split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = df['price'].copy()\n",
    "features = df[['points','year']].copy()\n",
    "#features = df.drop(['price'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.1, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 241.96\n",
      "R2: 0.33\n"
     ]
    }
   ],
   "source": [
    "#OLS with scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import *\n",
    "\n",
    "model_1 = LinearRegression()\n",
    "model_1.fit(X_train, y_train)\n",
    "\n",
    "#print regression score and mean squared error\n",
    "print(\"MSE: %.2f\"\n",
    "      % mean_squared_error(y_test, model_1.predict(X_test)))\n",
    "print('R2: %.2f' % r2_score(y_test, model_1.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 11199.13386979\n",
      "Iteration 2, loss = 188.80100046\n",
      "Iteration 3, loss = 187.34318473\n",
      "Iteration 4, loss = 184.62129360\n",
      "Iteration 5, loss = 180.62091259\n",
      "Iteration 6, loss = 178.92182361\n",
      "Iteration 7, loss = 181.50965788\n",
      "Iteration 8, loss = 173.55239175\n",
      "Iteration 9, loss = 166.21840954\n",
      "Iteration 10, loss = 165.46164511\n",
      "Iteration 11, loss = 159.02183025\n",
      "Iteration 12, loss = 156.41490098\n",
      "Iteration 13, loss = 148.54119281\n",
      "Iteration 14, loss = 151.89516552\n",
      "Iteration 15, loss = 147.37213436\n",
      "Iteration 16, loss = 141.89199989\n",
      "Iteration 17, loss = 150.64244761\n",
      "Iteration 18, loss = 141.93541381\n",
      "Iteration 19, loss = 138.55597169\n",
      "Iteration 20, loss = 136.80653282\n",
      "Iteration 21, loss = 138.79230747\n",
      "Iteration 22, loss = 133.99912238\n",
      "Iteration 23, loss = 139.59440694\n",
      "Iteration 24, loss = 158.04212174\n",
      "Iteration 25, loss = 184.73582420\n",
      "Iteration 26, loss = 183.31469493\n",
      "Iteration 27, loss = 180.34747729\n",
      "Iteration 28, loss = 179.69042458\n",
      "Iteration 29, loss = 177.20865470\n",
      "Iteration 30, loss = 171.16760248\n",
      "Iteration 31, loss = 157.78829719\n",
      "Iteration 32, loss = 151.20897168\n",
      "Iteration 33, loss = 144.92031475\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": "MLPRegressor(hidden_layer_sizes=(200, 200, 200), learning_rate='adaptive',\n             learning_rate_init=0.01, max_iter=1000, random_state=1, tol=1e-09,\n             verbose=10)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(200, 200, 200), learning_rate=&#x27;adaptive&#x27;,\n             learning_rate_init=0.01, max_iter=1000, random_state=1, tol=1e-09,\n             verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(200, 200, 200), learning_rate=&#x27;adaptive&#x27;,\n             learning_rate_init=0.01, max_iter=1000, random_state=1, tol=1e-09,\n             verbose=10)</pre></div></div></div></div></div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DNN with scikit-learn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model_sklearn = MLPRegressor(hidden_layer_sizes=(200,200,200), max_iter=1000, alpha=0.0001,\n",
    "                     solver='adam', verbose=10, tol=0.000000001, random_state=1,\n",
    "                     learning_rate_init=0.01, learning_rate='adaptive')\n",
    "\n",
    "model_sklearn.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 260.95\n",
      "R2: 0.27\n"
     ]
    }
   ],
   "source": [
    "#print regression score and mean squared error\n",
    "print(\"MSE: %.2f\"\n",
    "      % mean_squared_error(y_test, model_sklearn.predict(X_test)))\n",
    "print('R2: %.2f' % r2_score(y_test, model_sklearn.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 200)               600       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,201\n",
      "Trainable params: 81,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#DNN with tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "model_tf = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(200, activation='relu', input_shape=(2,)),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_tf.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse'])\n",
    "model_tf.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "819/819 [==============================] - 1s 901us/step - loss: 248.0702 - mae: 12.1694 - mse: 248.0702 - val_loss: 236.4492 - val_mae: 12.1808 - val_mse: 236.4492\n",
      "Epoch 2/100\n",
      "819/819 [==============================] - 1s 853us/step - loss: 246.8792 - mae: 12.1459 - mse: 246.8792 - val_loss: 236.2654 - val_mae: 12.1733 - val_mse: 236.2654\n",
      "Epoch 3/100\n",
      "819/819 [==============================] - 1s 833us/step - loss: 249.0831 - mae: 12.1811 - mse: 249.0831 - val_loss: 238.8452 - val_mae: 12.0383 - val_mse: 238.8452\n",
      "Epoch 4/100\n",
      "819/819 [==============================] - 1s 861us/step - loss: 247.8445 - mae: 12.1743 - mse: 247.8445 - val_loss: 237.4100 - val_mae: 11.7512 - val_mse: 237.4100\n",
      "Epoch 5/100\n",
      "819/819 [==============================] - 1s 832us/step - loss: 247.8345 - mae: 12.1804 - mse: 247.8345 - val_loss: 268.1567 - val_mae: 13.5293 - val_mse: 268.1567\n",
      "Epoch 6/100\n",
      "819/819 [==============================] - 1s 835us/step - loss: 245.1492 - mae: 12.1069 - mse: 245.1492 - val_loss: 231.8425 - val_mae: 11.6959 - val_mse: 231.8425\n",
      "Epoch 7/100\n",
      "819/819 [==============================] - 1s 817us/step - loss: 247.9612 - mae: 12.1711 - mse: 247.9612 - val_loss: 235.4129 - val_mae: 12.1129 - val_mse: 235.4129\n",
      "Epoch 8/100\n",
      "819/819 [==============================] - 1s 903us/step - loss: 247.4348 - mae: 12.1374 - mse: 247.4348 - val_loss: 235.0790 - val_mae: 12.1192 - val_mse: 235.0790\n",
      "Epoch 9/100\n",
      "819/819 [==============================] - 1s 866us/step - loss: 248.3134 - mae: 12.1833 - mse: 248.3134 - val_loss: 246.6929 - val_mae: 11.4999 - val_mse: 246.6929\n",
      "Epoch 10/100\n",
      "819/819 [==============================] - 1s 858us/step - loss: 247.9655 - mae: 12.1835 - mse: 247.9655 - val_loss: 240.1176 - val_mae: 11.4985 - val_mse: 240.1176\n",
      "Epoch 11/100\n",
      "819/819 [==============================] - 1s 880us/step - loss: 245.4735 - mae: 12.1008 - mse: 245.4735 - val_loss: 232.9580 - val_mae: 11.6112 - val_mse: 232.9580\n",
      "Epoch 12/100\n",
      "819/819 [==============================] - 1s 867us/step - loss: 246.8037 - mae: 12.1563 - mse: 246.8037 - val_loss: 234.9823 - val_mae: 11.6177 - val_mse: 234.9823\n",
      "Epoch 13/100\n",
      "819/819 [==============================] - 1s 885us/step - loss: 246.3561 - mae: 12.1110 - mse: 246.3561 - val_loss: 241.7862 - val_mae: 11.6089 - val_mse: 241.7862\n",
      "Epoch 14/100\n",
      "819/819 [==============================] - 1s 872us/step - loss: 246.6566 - mae: 12.1340 - mse: 246.6566 - val_loss: 271.6345 - val_mae: 13.6446 - val_mse: 271.6345\n",
      "Epoch 15/100\n",
      "819/819 [==============================] - 1s 818us/step - loss: 248.1082 - mae: 12.1766 - mse: 248.1082 - val_loss: 236.4041 - val_mae: 11.5365 - val_mse: 236.4041\n",
      "Epoch 16/100\n",
      "819/819 [==============================] - 1s 924us/step - loss: 248.6436 - mae: 12.1887 - mse: 248.6436 - val_loss: 251.3831 - val_mae: 11.5107 - val_mse: 251.3831\n",
      "Epoch 17/100\n",
      "819/819 [==============================] - 1s 863us/step - loss: 248.6968 - mae: 12.1924 - mse: 248.6968 - val_loss: 252.2357 - val_mae: 11.6106 - val_mse: 252.2357\n",
      "Epoch 18/100\n",
      "819/819 [==============================] - 1s 841us/step - loss: 248.0874 - mae: 12.1816 - mse: 248.0874 - val_loss: 232.2320 - val_mae: 11.6511 - val_mse: 232.2320\n",
      "Epoch 19/100\n",
      "819/819 [==============================] - 1s 859us/step - loss: 247.4138 - mae: 12.1696 - mse: 247.4138 - val_loss: 233.2724 - val_mae: 11.9407 - val_mse: 233.2724\n",
      "Epoch 20/100\n",
      "819/819 [==============================] - 1s 844us/step - loss: 247.1461 - mae: 12.1500 - mse: 247.1461 - val_loss: 236.7324 - val_mae: 12.2062 - val_mse: 236.7324\n",
      "Epoch 21/100\n",
      "819/819 [==============================] - 1s 871us/step - loss: 246.6290 - mae: 12.1304 - mse: 246.6290 - val_loss: 233.8527 - val_mae: 11.5970 - val_mse: 233.8527\n",
      "Epoch 22/100\n",
      "819/819 [==============================] - 1s 816us/step - loss: 246.1196 - mae: 12.1331 - mse: 246.1196 - val_loss: 233.8449 - val_mae: 11.7860 - val_mse: 233.8449\n",
      "Epoch 23/100\n",
      "819/819 [==============================] - 1s 850us/step - loss: 247.5813 - mae: 12.1732 - mse: 247.5813 - val_loss: 231.6147 - val_mae: 11.7493 - val_mse: 231.6147\n",
      "Epoch 24/100\n",
      "819/819 [==============================] - 1s 847us/step - loss: 247.0382 - mae: 12.1323 - mse: 247.0382 - val_loss: 232.9151 - val_mae: 11.7554 - val_mse: 232.9151\n",
      "Epoch 25/100\n",
      "819/819 [==============================] - 1s 849us/step - loss: 248.2285 - mae: 12.1787 - mse: 248.2285 - val_loss: 248.7242 - val_mae: 11.4812 - val_mse: 248.7242\n",
      "Epoch 26/100\n",
      "819/819 [==============================] - 1s 837us/step - loss: 247.4941 - mae: 12.1465 - mse: 247.4941 - val_loss: 232.8060 - val_mae: 11.8656 - val_mse: 232.8060\n",
      "Epoch 27/100\n",
      "819/819 [==============================] - 1s 835us/step - loss: 245.2372 - mae: 12.1057 - mse: 245.2372 - val_loss: 238.9310 - val_mae: 11.4637 - val_mse: 238.9310\n",
      "Epoch 28/100\n",
      "819/819 [==============================] - 1s 814us/step - loss: 248.4017 - mae: 12.1975 - mse: 248.4017 - val_loss: 232.1146 - val_mae: 11.7868 - val_mse: 232.1146\n",
      "Epoch 29/100\n",
      "819/819 [==============================] - 1s 831us/step - loss: 245.7308 - mae: 12.1188 - mse: 245.7308 - val_loss: 232.1393 - val_mae: 11.7932 - val_mse: 232.1393\n",
      "Epoch 30/100\n",
      "819/819 [==============================] - 1s 835us/step - loss: 248.3487 - mae: 12.1581 - mse: 248.3487 - val_loss: 236.9794 - val_mae: 12.2457 - val_mse: 236.9794\n",
      "Epoch 31/100\n",
      "819/819 [==============================] - 1s 841us/step - loss: 245.5399 - mae: 12.0981 - mse: 245.5399 - val_loss: 237.6426 - val_mae: 12.1971 - val_mse: 237.6426\n",
      "Epoch 32/100\n",
      "819/819 [==============================] - 1s 832us/step - loss: 246.5103 - mae: 12.1317 - mse: 246.5103 - val_loss: 294.0387 - val_mae: 12.1779 - val_mse: 294.0387\n",
      "Epoch 33/100\n",
      "819/819 [==============================] - 1s 833us/step - loss: 246.4605 - mae: 12.1543 - mse: 246.4605 - val_loss: 234.9565 - val_mae: 12.0909 - val_mse: 234.9565\n",
      "Epoch 34/100\n",
      "819/819 [==============================] - 1s 812us/step - loss: 245.7713 - mae: 12.0966 - mse: 245.7713 - val_loss: 259.1712 - val_mae: 11.6269 - val_mse: 259.1712\n",
      "Epoch 35/100\n",
      "819/819 [==============================] - 1s 819us/step - loss: 248.2441 - mae: 12.1980 - mse: 248.2441 - val_loss: 231.9569 - val_mae: 11.7321 - val_mse: 231.9569\n",
      "Epoch 36/100\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 246.9764 - mae: 12.1297 - mse: 246.9764 - val_loss: 235.3761 - val_mae: 11.7031 - val_mse: 235.3761\n",
      "Epoch 37/100\n",
      "819/819 [==============================] - 1s 826us/step - loss: 248.2621 - mae: 12.1867 - mse: 248.2621 - val_loss: 234.5240 - val_mae: 12.0499 - val_mse: 234.5240\n",
      "Epoch 38/100\n",
      "819/819 [==============================] - 1s 812us/step - loss: 244.3182 - mae: 12.0654 - mse: 244.3182 - val_loss: 234.8899 - val_mae: 12.0917 - val_mse: 234.8899\n",
      "Epoch 39/100\n",
      "819/819 [==============================] - 1s 815us/step - loss: 245.8990 - mae: 12.1218 - mse: 245.8990 - val_loss: 240.4219 - val_mae: 12.3680 - val_mse: 240.4219\n",
      "Epoch 40/100\n",
      "819/819 [==============================] - 1s 819us/step - loss: 245.1697 - mae: 12.0967 - mse: 245.1697 - val_loss: 231.8526 - val_mae: 11.6847 - val_mse: 231.8526\n",
      "Epoch 41/100\n",
      "819/819 [==============================] - 1s 809us/step - loss: 247.4369 - mae: 12.1561 - mse: 247.4369 - val_loss: 236.1681 - val_mae: 11.5433 - val_mse: 236.1681\n",
      "Epoch 42/100\n",
      "819/819 [==============================] - 1s 816us/step - loss: 244.8386 - mae: 12.0746 - mse: 244.8386 - val_loss: 232.2894 - val_mae: 11.8678 - val_mse: 232.2894\n",
      "Epoch 43/100\n",
      "819/819 [==============================] - 1s 815us/step - loss: 246.8089 - mae: 12.1392 - mse: 246.8089 - val_loss: 238.9274 - val_mae: 11.4555 - val_mse: 238.9274\n",
      "Epoch 44/100\n",
      "819/819 [==============================] - 1s 811us/step - loss: 247.8996 - mae: 12.1490 - mse: 247.8996 - val_loss: 246.4765 - val_mae: 11.6219 - val_mse: 246.4765\n",
      "Epoch 45/100\n",
      "819/819 [==============================] - 1s 812us/step - loss: 244.0867 - mae: 12.0770 - mse: 244.0867 - val_loss: 233.1999 - val_mae: 11.6083 - val_mse: 233.1999\n",
      "Epoch 46/100\n",
      "819/819 [==============================] - 1s 814us/step - loss: 247.0239 - mae: 12.1473 - mse: 247.0239 - val_loss: 247.6150 - val_mae: 11.6968 - val_mse: 247.6150\n",
      "Epoch 47/100\n",
      "819/819 [==============================] - 1s 817us/step - loss: 247.6413 - mae: 12.1631 - mse: 247.6413 - val_loss: 233.5043 - val_mae: 11.6348 - val_mse: 233.5043\n",
      "Epoch 48/100\n",
      "819/819 [==============================] - 1s 818us/step - loss: 245.7376 - mae: 12.1041 - mse: 245.7376 - val_loss: 236.5449 - val_mae: 12.1724 - val_mse: 236.5449\n",
      "Epoch 49/100\n",
      "819/819 [==============================] - 1s 809us/step - loss: 246.6395 - mae: 12.1423 - mse: 246.6395 - val_loss: 231.5434 - val_mae: 11.7246 - val_mse: 231.5434\n",
      "Epoch 50/100\n",
      "819/819 [==============================] - 1s 809us/step - loss: 244.9715 - mae: 12.0851 - mse: 244.9715 - val_loss: 231.8556 - val_mae: 11.7052 - val_mse: 231.8556\n",
      "Epoch 51/100\n",
      "819/819 [==============================] - 1s 832us/step - loss: 245.6748 - mae: 12.1150 - mse: 245.6748 - val_loss: 231.8394 - val_mae: 11.7500 - val_mse: 231.8394\n",
      "Epoch 52/100\n",
      "819/819 [==============================] - 1s 819us/step - loss: 246.0946 - mae: 12.1249 - mse: 246.0946 - val_loss: 241.5233 - val_mae: 11.5820 - val_mse: 241.5233\n",
      "Epoch 53/100\n",
      "819/819 [==============================] - 1s 836us/step - loss: 245.8478 - mae: 12.1156 - mse: 245.8478 - val_loss: 243.5592 - val_mae: 12.5718 - val_mse: 243.5592\n",
      "Epoch 54/100\n",
      "819/819 [==============================] - 1s 810us/step - loss: 247.6529 - mae: 12.1569 - mse: 247.6529 - val_loss: 231.8081 - val_mae: 11.7692 - val_mse: 231.8081\n",
      "Epoch 55/100\n",
      "819/819 [==============================] - 1s 816us/step - loss: 244.9502 - mae: 12.0753 - mse: 244.9502 - val_loss: 255.7909 - val_mae: 11.5187 - val_mse: 255.7909\n",
      "Epoch 56/100\n",
      "819/819 [==============================] - 1s 822us/step - loss: 245.9823 - mae: 12.1263 - mse: 245.9823 - val_loss: 232.1745 - val_mae: 11.6290 - val_mse: 232.1745\n",
      "Epoch 57/100\n",
      "819/819 [==============================] - 1s 810us/step - loss: 246.4095 - mae: 12.1387 - mse: 246.4095 - val_loss: 233.2371 - val_mae: 11.5457 - val_mse: 233.2371\n",
      "Epoch 58/100\n",
      "819/819 [==============================] - 1s 860us/step - loss: 247.3362 - mae: 12.1520 - mse: 247.3362 - val_loss: 232.4455 - val_mae: 11.8892 - val_mse: 232.4455\n",
      "Epoch 59/100\n",
      "819/819 [==============================] - 1s 819us/step - loss: 244.8427 - mae: 12.0839 - mse: 244.8427 - val_loss: 239.8945 - val_mae: 12.3636 - val_mse: 239.8945\n",
      "Epoch 60/100\n",
      "819/819 [==============================] - 1s 823us/step - loss: 245.3782 - mae: 12.1123 - mse: 245.3782 - val_loss: 265.0874 - val_mae: 11.7607 - val_mse: 265.0874\n",
      "Epoch 61/100\n",
      "819/819 [==============================] - 1s 824us/step - loss: 246.2493 - mae: 12.1309 - mse: 246.2493 - val_loss: 240.5507 - val_mae: 12.3369 - val_mse: 240.5507\n",
      "Epoch 62/100\n",
      "819/819 [==============================] - 1s 832us/step - loss: 243.7103 - mae: 12.0569 - mse: 243.7103 - val_loss: 237.7012 - val_mae: 12.2640 - val_mse: 237.7012\n",
      "Epoch 63/100\n",
      "819/819 [==============================] - 1s 833us/step - loss: 246.3669 - mae: 12.1170 - mse: 246.3669 - val_loss: 240.8829 - val_mae: 12.4754 - val_mse: 240.8829\n",
      "Epoch 64/100\n",
      "819/819 [==============================] - 1s 867us/step - loss: 246.0867 - mae: 12.1128 - mse: 246.0867 - val_loss: 237.5974 - val_mae: 12.2871 - val_mse: 237.5974\n",
      "Epoch 65/100\n",
      "819/819 [==============================] - 1s 990us/step - loss: 247.5047 - mae: 12.1709 - mse: 247.5047 - val_loss: 246.6066 - val_mae: 12.6443 - val_mse: 246.6066\n",
      "Epoch 66/100\n",
      "819/819 [==============================] - 1s 870us/step - loss: 245.9868 - mae: 12.1191 - mse: 245.9868 - val_loss: 233.7549 - val_mae: 12.0101 - val_mse: 233.7549\n",
      "Epoch 67/100\n",
      "819/819 [==============================] - 1s 855us/step - loss: 244.4253 - mae: 12.0623 - mse: 244.4253 - val_loss: 234.3452 - val_mae: 11.6020 - val_mse: 234.3452\n",
      "Epoch 68/100\n",
      "819/819 [==============================] - 1s 850us/step - loss: 246.1439 - mae: 12.1163 - mse: 246.1439 - val_loss: 232.8688 - val_mae: 11.9277 - val_mse: 232.8688\n",
      "Epoch 69/100\n",
      "819/819 [==============================] - 1s 820us/step - loss: 245.0107 - mae: 12.0907 - mse: 245.0107 - val_loss: 232.1083 - val_mae: 11.5814 - val_mse: 232.1083\n",
      "Epoch 70/100\n",
      "819/819 [==============================] - 1s 812us/step - loss: 248.1867 - mae: 12.1759 - mse: 248.1867 - val_loss: 239.4141 - val_mae: 11.6316 - val_mse: 239.4141\n",
      "Epoch 71/100\n",
      "819/819 [==============================] - 1s 833us/step - loss: 246.8120 - mae: 12.1409 - mse: 246.8120 - val_loss: 243.8371 - val_mae: 12.5917 - val_mse: 243.8371\n",
      "Epoch 72/100\n",
      "819/819 [==============================] - 1s 812us/step - loss: 245.2967 - mae: 12.1143 - mse: 245.2967 - val_loss: 231.9194 - val_mae: 11.7983 - val_mse: 231.9194\n",
      "Epoch 73/100\n",
      "819/819 [==============================] - 1s 811us/step - loss: 244.9850 - mae: 12.0810 - mse: 244.9850 - val_loss: 308.7695 - val_mae: 14.7553 - val_mse: 308.7695\n",
      "Epoch 74/100\n",
      "819/819 [==============================] - 1s 815us/step - loss: 245.5197 - mae: 12.1059 - mse: 245.5197 - val_loss: 233.1447 - val_mae: 11.8308 - val_mse: 233.1447\n",
      "Epoch 75/100\n",
      "819/819 [==============================] - 1s 839us/step - loss: 247.0738 - mae: 12.1412 - mse: 247.0738 - val_loss: 236.5959 - val_mae: 11.5589 - val_mse: 236.5959\n",
      "Epoch 76/100\n",
      "819/819 [==============================] - 1s 842us/step - loss: 247.3496 - mae: 12.1554 - mse: 247.3496 - val_loss: 247.6263 - val_mae: 12.7200 - val_mse: 247.6263\n",
      "Epoch 77/100\n",
      "819/819 [==============================] - 1s 845us/step - loss: 247.1537 - mae: 12.1566 - mse: 247.1537 - val_loss: 239.7528 - val_mae: 11.5079 - val_mse: 239.7528\n",
      "Epoch 78/100\n",
      "819/819 [==============================] - 1s 812us/step - loss: 244.3733 - mae: 12.0846 - mse: 244.3733 - val_loss: 233.9649 - val_mae: 11.4946 - val_mse: 233.9649\n",
      "Epoch 79/100\n",
      "819/819 [==============================] - 1s 848us/step - loss: 244.4369 - mae: 12.0761 - mse: 244.4369 - val_loss: 231.9011 - val_mae: 11.8407 - val_mse: 231.9011\n",
      "Epoch 80/100\n",
      "819/819 [==============================] - 1s 853us/step - loss: 246.3535 - mae: 12.1202 - mse: 246.3535 - val_loss: 233.8353 - val_mae: 11.9873 - val_mse: 233.8353\n",
      "Epoch 81/100\n",
      "819/819 [==============================] - 1s 819us/step - loss: 245.8852 - mae: 12.1149 - mse: 245.8852 - val_loss: 251.5920 - val_mae: 11.5364 - val_mse: 251.5920\n",
      "Epoch 82/100\n",
      "819/819 [==============================] - 1s 922us/step - loss: 244.8917 - mae: 12.0893 - mse: 244.8917 - val_loss: 238.1342 - val_mae: 12.2982 - val_mse: 238.1342\n",
      "Epoch 83/100\n",
      "819/819 [==============================] - 1s 813us/step - loss: 243.5362 - mae: 12.0500 - mse: 243.5362 - val_loss: 232.0084 - val_mae: 11.8478 - val_mse: 232.0084\n",
      "Epoch 84/100\n",
      "819/819 [==============================] - 1s 818us/step - loss: 245.5836 - mae: 12.1047 - mse: 245.5836 - val_loss: 236.1149 - val_mae: 11.5222 - val_mse: 236.1149\n",
      "Epoch 85/100\n",
      "819/819 [==============================] - 1s 819us/step - loss: 245.1879 - mae: 12.1022 - mse: 245.1879 - val_loss: 236.2203 - val_mae: 12.1238 - val_mse: 236.2203\n",
      "Epoch 86/100\n",
      "819/819 [==============================] - 1s 854us/step - loss: 245.2338 - mae: 12.0979 - mse: 245.2338 - val_loss: 233.8818 - val_mae: 12.0039 - val_mse: 233.8818\n",
      "Epoch 87/100\n",
      "819/819 [==============================] - 1s 846us/step - loss: 244.7260 - mae: 12.0982 - mse: 244.7260 - val_loss: 240.7741 - val_mae: 12.4187 - val_mse: 240.7741\n",
      "Epoch 88/100\n",
      "819/819 [==============================] - 1s 848us/step - loss: 246.0141 - mae: 12.1219 - mse: 246.0141 - val_loss: 256.9781 - val_mae: 13.1489 - val_mse: 256.9781\n",
      "Epoch 89/100\n",
      "819/819 [==============================] - 1s 844us/step - loss: 245.7648 - mae: 12.1058 - mse: 245.7648 - val_loss: 232.8489 - val_mae: 11.9453 - val_mse: 232.8489\n",
      "Epoch 90/100\n",
      "819/819 [==============================] - 1s 904us/step - loss: 246.7029 - mae: 12.1198 - mse: 246.7029 - val_loss: 240.5897 - val_mae: 11.5288 - val_mse: 240.5897\n",
      "Epoch 91/100\n",
      "819/819 [==============================] - 1s 841us/step - loss: 244.9377 - mae: 12.0802 - mse: 244.9377 - val_loss: 239.1700 - val_mae: 11.6360 - val_mse: 239.1700\n",
      "Epoch 92/100\n",
      "819/819 [==============================] - 1s 879us/step - loss: 245.5972 - mae: 12.1003 - mse: 245.5972 - val_loss: 235.3186 - val_mae: 11.5293 - val_mse: 235.3186\n",
      "Epoch 93/100\n",
      "819/819 [==============================] - 1s 856us/step - loss: 244.3976 - mae: 12.0733 - mse: 244.3976 - val_loss: 233.8646 - val_mae: 12.0212 - val_mse: 233.8646\n",
      "Epoch 94/100\n",
      "819/819 [==============================] - 1s 809us/step - loss: 246.0000 - mae: 12.1221 - mse: 246.0000 - val_loss: 238.1579 - val_mae: 12.3320 - val_mse: 238.1579\n",
      "Epoch 95/100\n",
      "819/819 [==============================] - 1s 811us/step - loss: 244.4213 - mae: 12.0918 - mse: 244.4213 - val_loss: 239.5725 - val_mae: 11.5183 - val_mse: 239.5725\n",
      "Epoch 96/100\n",
      "819/819 [==============================] - 1s 814us/step - loss: 246.5888 - mae: 12.1147 - mse: 246.5888 - val_loss: 234.6654 - val_mae: 12.1086 - val_mse: 234.6654\n",
      "Epoch 97/100\n",
      "819/819 [==============================] - 1s 813us/step - loss: 244.0779 - mae: 12.0691 - mse: 244.0779 - val_loss: 232.0739 - val_mae: 11.6603 - val_mse: 232.0739\n",
      "Epoch 98/100\n",
      "819/819 [==============================] - 1s 870us/step - loss: 244.7387 - mae: 12.0914 - mse: 244.7387 - val_loss: 233.3216 - val_mae: 11.5166 - val_mse: 233.3216\n",
      "Epoch 99/100\n",
      "819/819 [==============================] - 1s 850us/step - loss: 245.0670 - mae: 12.0858 - mse: 245.0670 - val_loss: 235.6677 - val_mae: 12.1818 - val_mse: 235.6677\n",
      "Epoch 100/100\n",
      "819/819 [==============================] - 1s 855us/step - loss: 244.1453 - mae: 12.0782 - mse: 244.1453 - val_loss: 242.5709 - val_mae: 11.4895 - val_mse: 242.5709\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x292f903d0>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf.fit(X_train, y_train, epochs=100, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 246.55\n",
      "R2: 0.31\n"
     ]
    }
   ],
   "source": [
    "#print regression score and mean squared error\n",
    "print(\"MSE: %.2f\"\n",
    "      % mean_squared_error(y_test, model_tf.predict(X_test)))\n",
    "print('R2: %.2f' % r2_score(y_test, model_tf.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}